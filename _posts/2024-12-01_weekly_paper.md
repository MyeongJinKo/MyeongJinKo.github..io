---
title: "high-dimensional clustering 해결방법 및 주성분과 요인분석"
author : Myeong Jin Ko
date : 2024-12-01 08:00:00 UTC+9
tags: [Codeit_WeeklyPaper]
---

## Weekly-Paper with odeit Data_Analyst_4
---
### high-dimensional clustering

**high-dimensional clustering**이란 데이터를 클러스터링 할 때 차원이 너무 많아 발생하게 된다.
<br>더 자세히 들어가기 전에 **차원**에 대해 먼저 알아보고 고차원문제 해결방법을 알아보기 한다.

**차원(Dimensional)**
머신러닝에서 "차원"은 데이터를 설명하기 위해 사용하는 특징(Feature), 변수(Variable)의 "개수"를 의미한다.

차원의 예시
<br>
- 1차원 : 학생들의 수학 성적(Math_Score) -> 수학 성적이라는 "한가지" 변수만 존재할 때 1차원
- 2차원 : 학생들의 수학(Math_Score), 영어(English_Score) 성적 -> 수학, 영어점수 즉 "두가지" 변수가 존재할 때 2차원
- 3차원 : 학생들의 수학(Math_Score), 영어(English_Score), 과학(Science_Score) 성적 -> 수학, 영어, 과학점수 총 "세가지" 변수가 존재할 때 3차원
- 고차원 : 보통 4개 이상의 변수가 들어갈 경우 고차원데이터로 말한다.

여기서 주목해야 될 점은 바로 "고차원"이다.
고차원 데이터는 주로 4개 이상의 특징(feature) 또는 변수(variable)가 존재한다는 뜻으로 차원이 많아져서 시각화가 어렵고 계산량이 증가하게 된다.
차원이 수십~수백개가 넘어갈 경우 앞서 언급했던 **high_dimensional clustering**이 발생하게 되며
클러스터링의 정확도가 낮아질 수 있다.

따라서 머신러닝 모델 구축에 필요한 데이터셋의 변수가 많을 경우 차원을 축소해서 고차원에서 낮은차원으로 바꿔주어야 정확도를 높일 수 있다.

### high-dimensional clustering 해결방법
고차원 데이터를 저차원 데이터로 변경하기 위해서는 아래 방법을 사용할 수 있다.

해결방법
<br>
차원축소 방식에는 크게 선형 방법과 비선형 방법이 존재한다.
<br>
- 선형방법
  - 주성분 분석(PCA) : 가장 일반적인 차원 축소 방법. 데이터 셋의 원래 특징을 결합하고 변환하여 주성분이라는 새로운 특징을 생성하는 특징추출의 형태
  - 독립성분 분석(ICA) : 신호처리와 데이터 분석에서 사용되는 통계적 기법이다. 예를 들어 같이 녹음된 두 목소리를 서로 분리하는 것, 뇌파 데이터 분석, 이미지 패턴이나 잡음 제거
  - 선형 판별 분석(LDA) : 데이터의 클래스 차이를 최대화하는 구성 변수를 생성하는 기법이다. 예를 들어 얼굴 인식 분류기, 생체 데이터 분석기
  - PCA와 LDA의 차이점 : LDA는 클래스 레이블 정보를 사용하여 클래스 간 분리(차이)를 최대화 하지만, PCA는 데이터의 전체 분산을 최대화하며, 클래스 레이블을 사용하지 않는다.
 
- 비선형 방법
  - 매니폴드 학습(Manifold) : 
  - t-분포 확률적 임베딩(t-SNE) : 차원축소 방ㅅ


---
### 기술통계와 추론통계

**기술통계** : 데이터를 요약하고 정리하여 쉽게 이해할 수 있도록 만드는 방법. 숫자나 그래프 이용하여 데이터의 주요 통계를 확인
  - 주요 기법 : 중심경향치, 산포도, 시각적 표현

**추론통계** : 표본 데이터를 바탕으로 모집단의 특성을 추정하거나 가설을 검정하는 통계방법이다.
  - 주요 기법 : 추정. 가설검정, 회귀분석, 확률분포

**차이점** : 
  - 기술통계는 데이터를 요약하고 설명하는 특징이 있는 반면에 추론통계는 모집단에 대해 추론하거나 예측을 하는 목적을 갖는다.
  - 기술통계는 전체 데이터를 사용하나 추론통계는 표본 데이터를 바탕으로 무집단을 추정한다.
  - 기술통계는 단순 데이터 분석을 하지만 추론통계는 가설 검정, 예측, 모델 구축으로 활용된다.
